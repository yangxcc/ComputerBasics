## Redis底层的数据结构

Redis是由C语言编写的，它支持5中数据类型，以K-V形式进行存储，K是String类型，V可以是String、list、hash、Set、ZSet5种数据结构，每种数据结构都有各自对应的场景



### String

我们知道虽然Redis是使用C语言编写的，但是对于String类型Redis并不是使用的C语言中的字符串，Redis是自己构建了一种名为简单动态字符串**（SDS）**的抽象类型，并将SDS作为Redis的默认字符串表示

SDS的定义如下：

```c
struct sdshdr{
   //记录buf数组中已使用字节的数量
   //等于 SDS 保存字符串的长度
   int len;
   //记录 buf 数组中未使用字节的数量
   int free;
   //字节数组，用于保存字符串
   char buf[];
}
```

<img src="../../image/redis/image-20211218163651888.png" alt="image-20211218163651888" style="zoom:67%;" />

所以不使用C语言中提供的字符串类型，而是自己定义一个SDS的好处如下：

- **常数时间复杂度下（O(1)）就能够获取字符串长度**，对于SDS来说，只需要读取`len`属性就能够得到字符串的长度，但是对于C语言中的字符串来说，获得字符串的长度需要遍历整个字符串

- **杜绝缓冲区溢出**，我们知道在C语言中使用`strcat`函数来进行两个字符串拼接时，一旦没有分配足够长度的内存空间，就会造成缓冲区的溢出，而对于SDS数据类型，在进行字符串修改时首先会根据字符串的`len`属性来检查内存空间是否够用，如果不满足会进行相应的内存扩充，然后再进行修改操作，不会产生内存溢出的现象

  >[Redis底层数据结构解析(BAT大厂必问) - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/334664445#:~:text= Redis底层数据结构有以下数据类型：简单动态字符串（SDS），链表，字典，跳跃表，整数集合，压缩列表，对象。 接下来，就探讨一下Redis是怎么通过这些数据结构来实现value的5种类型的。 简单动态字符串（simple,dynamic string SDS） String的数据类型是由SDS实现的。)

- **减少修改字符串的内存重新分配次数，**C语言由于不记录字符串的长度，所以如果要修改字符串，必须要重新分配内存（先释放再申请），因为如果没有重新分配的话，字符串增大会造成内存溢出，字符串减小会造成内存泄漏

  而对于SDS来说，**由于len和free属性的存在，对于修改字符串SDS实现了空间预分配和惰性空间释放两种策略**

  - 空间预分配：对字符串进行空间扩充的时候，扩展的内存比实际需要的多，这样可以减少连续执行字符串增长操作所需要的内存重分配次数
  - 惰性空间释放：对于字符串进行缩短操作时，程序不立即使用内存重新分配来回收缩短后多余的字节，而是使用free属性将这些字节记录下来，等待后续使用（当然SDS也提供了相应的API，当我们有需要的时候可以手动释放这些未使用的空间）

- **二进制安全，**因为C字符串以空字符作为字符串结束的标识，而对于一些二进制文件（比如图片等），内容可能包含空字符串，所以C字符串无法正确的读取，但是SDS的API都是以处理二进制的方式来处理buf里面的元素，而且SDS不是以空字符串来判断是否结束，而是通过`len`属性表示的长度来判断字符串是否结束

> 值得注意的是，在Redis中，SDS不仅仅是只能够用来保存数据库的字符串值，他还可以**被用作缓冲区（buffer）**：包括AOF模块中的AOF缓冲区以及客户端状态中的输入缓冲区



此外，Redis为了将内存的使用率做到极致，针对字符串对象，提供了三种数据结构，如下所示

```c
REDIS_ENCODING_INT（long 类型的整数）
REDIS_ENCODING_EMBSTR embstr （编码的简单动态字符串）
REDIS_ENCODING_RAW （简单动态字符串）
```

- **如果一个字符串内容可转为 long，那么该字符串会被转化为 long 类型，**对象 ptr直接存储该值，并将 encoding 设置为 int，这样就不需要重新开辟空间，算是长整形的一个优化。

- 如果字符串对象保存的是一个字符串值，并且这个字符串的长度小于等于 44 字节，那么字符串对象将使用 embstr 编码的方式来保存这个字符串。

  > 3.2版本之后是44个字节，之前是39个字节，这也是因为sds结构的版本变化所导致的。

  embstr类型是如何存放字符串的**【重点】**

  **我们知道一般cpu从内存中读取数据会先读取到 cache line（缓存行）， 一个缓存行基本占64个字节，其中redisObject最少占16个字节（根据属性的类型计算得出），所以如果要读取一个 redisObject，会发现只读取了16个字节，剩下的48个字节的空间相当于浪费，所以为了提高性能（主要减少了内存读取的次数），所以在RedisObject空间后又开辟48个字节的连续空间，将ptr指向的值存入其中，注意此处存入的是字符串类型，48个字节对应的是sdshdr8存储结构。而 sdshdr8 在不存入数据的情况下，最少要 4 个字节（其中一个字节是字符串尾部的'\0'）,那么还剩余 44 个字节，所以如果在 44 个字节以内字符串就可以放在缓存行里面，从而减少了内存I/O次数**

  > 类似于预读功能，作用就是减少内存IO的次数

- 如果字符串对象保存的是一个字符串值，并且**这个字符串的长度大于 32 字节，那么字符串对象将使用一个简单动态字符串（SDS）来保存这个字符串值，并将对象的编码设置为 raw**。

>[Redis极致设计-五大数据结构的底层结构原理 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/349981906)



### List

C语言的内部没有内置这种数据结构，所以Redis自己使用了链表

list的底层数据结构在3.2版本之前有两种，一种是linkedlist（双向链表），另一种是ziplist

在3.2版本之后升级成为了quicklist（双向链表）

<img src="../../image/redis/image-20211218170559448.png" alt="image-20211218170559448" style="zoom:67%;" />

- `dup`：用于复制链表节点所保存的值
- `free`：用于释放链表节点所保存的值
- `match`：用于对比链表节点所保存的值和另一个输入值是否相等

Redis链表的特性是双端、无环、带链表长度计数器、多态

　　①、双端：链表具有前置节点和后置节点的引用，获取这两个节点时间复杂度都为O(1)。

　　②、无环：表头节点的 prev 指针和表尾节点的 next 指针都指向 NULL,对链表的访问都是以 NULL 结束。　　

　　③、带链表长度计数器：通过 len 属性获取链表长度的时间复杂度为 O(1)。

　　④、多态：链表节点使用 void* 指针来保存节点值，可以保存各种不同类型的值。

> 有关ziplist和quicklist的介绍[Redis极致设计-五大数据结构的底层结构原理 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/349981906)



### Hash

**hash的底层存储有两种数据结构，一种是ziplist，另外一种是hashtable**，当hash对象可以同时满足以下两个条件的时候，哈希对象使用ziplist编码：

- 哈希对象保存的所有键值对的键和值的字符串都小于64字节
- 哈希对象保存的键值对数量小于512个



压缩列表（ziplist）是Redis为了节省内存而开发的，是**由一系列特殊编码的连续内存块组成的顺序型数据结构**，一个压缩列表可以包含任意多个节点（entry），每个节点可以保存一个字节数组或者一个整数值。

**压缩列表的原理：压缩列表并不是对数据利用某种算法进行压缩，而是将数据按照一定规则编码在一块连续的内存区域，目的是节省内存**

**ziplist的存储结构如下：**

![preview](../../image/redis/v2-c77eed3b9cd76dbb511494ae0b25aeeb_r.jpg)

上图可以看到，当数据量比较小的时候，我们会将所有的key和value都当成一个元素，顺序的存入ziplist中，构成有序

更具体一点ziplist的结构是

![preview](../../image/redis/v2-a186babeb286169317e92dbfa6d4fa78_r.jpg)

其中黄色区域用来表示列表的特征，绿色区域就是列表中具体的元素了，**ziplist是使用连续的内存块存储的**

- zlbytes：表示整个ziplist占用的字节数，一般用于内存重分配或者计算列表尾端
- zltail：到达列表最后一个节点的偏移量，方便直接找到尾部节点
- zllen：列表节点的数量

> 注意zllen用16个比特位存储，也就是说起长度最大表示65535，所以如果长度超过这个值，只能够通过节点遍历来确定列表元素数量

- entryX：列表中的各节点
- zlend：作用就是用来标记列表尾端，占用一个字节

**ziplist最大的缺点就是连锁更新问题**

前面说过，每个节点的previous_entry length 属性都记录了前一个节点的长度：

- 如果前一节点的长度小于254 字节，那么previ ous* entry_length 属性需要用 1字节长的空间来保存这个长度值。
- 如果前一节点的长度大于等于254 字节，那么previous entry length 属性需要用5 字节长的空间来保存这个长度值。

如果我们将一个长度大于等于 254 字节的新节点 new 设置为压缩列表的表头节点，那么麻烦的事情来了，由于previous entry length大小不够用(1->5B)，**后面所有的节点可能都要重新分配内存大小**。因为连锁更新在最坏情况下需要对压缩列表执行 N 次空间重分配操作， 而每次空间重分配的最坏复杂度为 O(N) ， 所以连锁更新的最坏复杂度为 O(N^2) 。



**hash table哈希表的结构是**

<img src="../../image/redis/image-20211218173618050.png" alt="image-20211218173618050" style="zoom:67%;" />

我们知道哈希表最大的问题就是存在哈希冲突，**Redis中是通过链地址法解决的哈希冲突**，即通过next指针将多个哈希值相同的键值对连接在一起，用来解决哈希冲突

> 求索引就是利用计算出来的hash值 % sizemask



**哈希表的扩容和缩容**

当哈希表保存的键值对太多或者太少时，就要通过`rehash`重新散列来对哈希表进行相应的扩展或者收缩，具体步骤如下：

- 如果执行扩展操作，每次的扩展都是根据原哈希表已使用的空间扩大一倍创建另一个哈希表。相反，如果执行的是收缩操作，每次收缩根据已使用空间缩小一倍创建一个新的哈希表
- 然后再重新计算hash值和索引，将键值放到新的哈希表的位置上
- 所有键值对都迁移完毕之后，释放原哈希表的内存空间

**触发扩容的条件：**

- 服务器目前没有执行 BGSAVE 命令或者 BGREWRITEAOF 命令，并且负载因子大于等于1。
- 服务器目前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令，并且负载因子大于等于5。

> 负载因子 = 哈希表已保存节点数量 / 哈希表大小。

同时Redis中的扩容或者缩容是**渐进式`rehash`**，也就是说扩容和缩容操作不是一次性、集中式完成，而是分多次、渐进式完成的，这其实也不难理解，如果保存在Redis中的键值对只有几十个、上百个，那么`rehash`操作可能瞬间就可以完成，但是如果Redis中的数据有上百万条，几千万甚至更多，如果要进行一次性`rehash`势必会造成Redis一段时间内不能进行别的操作，所以Redis采用渐进式`rehash`，在进行渐进式`rehash`的期间，字典的删除、更新、查找操作可能在两个哈希表上进行，第一个哈希表没有找到，就回去第二个哈希表上找，但是增加操作一定是在新的哈希表上进行的



### Set

**Set底层用两种数据结构存储，一个是hashtable，一个是intset。**

set的底层存储intset和hashtable是存在编码转换的，使用**intset**存储必须满足下面两个条件，否则使用hashtable，条件如下：

- 结合对象保存的所有元素都是整数值
- 集合对象保存的元素数量不超过512个

**整数集合（intset）是Redis用于保存整数值的集合抽象数据类型，它可以保存类型为int16_t、int32_t 或者int64_t 的整数值，并且保证集合中不会出现重复元素。**

```c
typedef struct intset{
     //编码方式
     uint32_t encoding;
     //集合包含的元素数量
     uint32_t length;
     //保存元素的数组
     int8_t contents[];
 
}intset;
// 集合中的每个元素都是contents数组的一个数据项，他们按照从小到大的顺序排列，并且不包含任何的重复项，在intset中查找数据的时候是通过二分来查找的
// 需要注意的是虽然 contents 数组声明为 int8_t 类型，但是实际上contents 数组并不保存任何 int8_t 类型的值，其真正类型由 encoding 来决定。
```



### ZSet

**ZSet的底层实现是字典+跳表，使用skiplist按序保存元素及分值，使用dict来保存元素和分值的映射关系**

当同时满足下面两个条件的时候，ZSet使用的是ziplist来存储的

- 有序集合保存的元素数量小于128个
- 有序集合保存的所有元素的长度小于64字节



首先，跳表是一种有序的数据结构，它通过每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的，具有如下性质：

1. 有很多层结构组成
2. 每一层都是一个有序的链表，排列顺序由高层到低层，都至少包含两个链表节点，分别是前面的head节点和后面的nil节点
3. 最底层的链表包含了所有的元素
4. 如果一个元素出现在某一层的链表中，那么该层之下的链表也全都会出现（上一层的元素是当前层元素的子集）
5. 链表中每个节点都包含两个指针，一个指向同一层的下一个链表节点，另一个指向下一层的同一个链表节点

![image-20211218192546277](../../image/redis/image-20211218192546277.png)



- **搜索：**从最高层的链表节点开始，如果比当前节点要大和比当前层的下一个节点要小，那么则往下找，也就是和当前层的下一层的节点的下一个节点进行比较，以此类推，一直找到最底层的最后一个节点，如果找到则返回，反之则返回空。
- **插入：**首先确定插入的层数，有一种方法是假设**抛一枚硬币（跳表的时间复杂度通过概率能够算出来是..）**，如果是正面就累加，直到遇见反面为止，最后记录正面的次数作为插入的层数。当确定插入的层数k后，则需要将新元素插入到从底层到k层。
- **删除：**在各个层中找到包含指定值的节点，然后将节点从链表中删除即可，如果删除以后只剩下头尾两个节点，则删除这一层。



![img_5d1114e2e073517b3557367f72145522.png](../../image/redis/img_5d1114e2e073517b3557367f72145522.png)



## Redis主从复制

### 主从复制概述

<font color=red>Redis的高可用方案包括：持久化、主从复制（以及读写分离）、哨兵和集群，其中持久化解决的是Redis数据的单机备份问题（从内存到硬盘的备份），而主从复制则侧重解决数据的多机热备份，此外，主从复制还可以实现负载均衡和故障恢复</font>

所谓主从复制，就是将一台Redis服务器上的数据复制到其他Redis服务器上，前者称为主节点（master），后者成为从节点（slave）：**数据的复制是单向的，只能从主节点复制到从节点**

默认情况下，每台Redis服务器都是主节点，且一个主节点可以有多个从节点（或者没有从节点），但是一个从节点只能够有一个主节点

**主从复制的作用**

- **数据冗余**，主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式
- **故障恢复**，当主节点出现问题的时候，可以由从节点提供服务，实现快速的故障恢复，实际上是一种服务的冗余
- **负载均衡**，在主从复制的基础上，搭配上读写分离，可以由主节点提供写服务，从节点提供读服务（即写Redis数据的时候应用连接到主节点，读Redis数据的时候应用连接到从节点），分担服务器负载，尤其是在写少读多的场景下，通常通过多个从节点分担读负载，可以大大提高Redis的并发量
- **高可用基石**，主从复制是哨兵模式和集群能够实施的基础，因此可以说是主从复制是Redis高可用的基石



### 主从复制的实现原理

<font color=red>主从复制的过程大致上可以分成三个部分：连接建立阶段（准备阶段）、数据同步阶段、命令传播阶段</font>

#### 连接建立阶段

该阶段的主要作用是在主从节点之间建立连接，为数据同步做好准备

- **步骤一：保存主节点信息**

  从节点服务器内部维护了两个字段，即masterhost和masterport，用于存储主节点的ip和port信息

  需要注意的是，salveof是异步命令，从节点完成主节点ip和port的保存后，向发送salveof命令的客户端直接返回OK，实际的复制操作在这之后才开始进行

- **步骤二：建立socket连接**

  从节点每秒1次调用复制定时函数`replicationCron()`，如果发现了有主节点可以连接，便会根据主节点的ip和port，创建socket连接，如果连接成功，则：

  - 从节点：为该socket创建一个专门处理复制工作的文件事件处理器，负责后续的复制工作，如接收RDB文件、接收命令传播等
  - 主节点：接收到从节点的socket连接后（即accept之后），为该socket创建相应的客户端状态，并将从节点看做是连接到主节点的一个客户端，后面的步骤会以从节点向主节点发送命令请求的方式来进行

- **步骤三：发送ping命令**

  从节点称为主节点的客户端之后，发送ping命令进行首次请求，目的是检查socket连接是否可用，以及主节点当前是否能够处理请求

  从节点发送ping命令之后，可能会有三种情况：

  - 发送pong，说明socket连接正常，且主节点当前可以处理请求，复制过程继续
  - 超时，一定时间后从节点仍未收到主节点的回复，说明socket连接不可用，则从节点断开socket连接，并重连
  - 返回pong以外的结果，如果主节点返回其他结果，如正在处理超时运行的脚本，说明主节点当前无法处理命令，则从节点断开socket连接，并重连

- **步骤四：身份验证**

  如果从节点中设置了masterauth选项，则从节点需要向主节点进行身份验证；没有设置该选项，则不需要验证。从节点进行身份验证是通过向主节点发送auth命令进行的，auth命令的参数即为配置文件中的masterauth的值。

  如果主节点设置密码的状态，与从节点masterauth的状态一致（一致是指都存在，且密码相同，或者都不存在），则身份验证通过，复制过程继续；如果不一致，则从节点断开socket连接，并重连。

- **步骤五：发送从节点端口信息**

  身份验证之后，从节点会向主节点发送其监听的端口号，主节点将该信息保存到该从节点对应的客户端的`slave_listening_port`字段中，该端口信息除了在主节点中执行`info replication`时显示之外，没有其他任何作用



#### 数据同步阶段

数据同步阶段是主从复制最核心的阶段，主从节点之间的连接建立之后，便可以开始进行数据同步，该阶段可以理解为从节点数据的初始化，具体执行的方式是从节点向主节点发送`psync`命令，开始进行同步。

**根据主从节点当前状态的不同，可以分成全量复制和增量复制**

> 需要注意的是，在数据同步阶段之前：从节点是主节点的客户端，主节点不是从节点的客户端，而到了数据同步节点以及后面的命令传播阶段：主从节点互为客户端，原因在于：在连接建立阶段，主节点只需要响应从节点的请求，不需要向从节点发送请求，而在后面的两个阶段，**主节点需要主动向从节点发送请求（如推送缓冲区中的写命令），才能完成复制。**



#### 命令传播阶段

在这个阶段主节点将自己执行的写命令发送给从节点，从节点接受命令并执行，从而保证主从节点数据的一致性

在命令传播阶段，除了发送写命令，主从节点还维持着**心跳机制**

但是需要注意的是，命令传播是一个异步的过程，即主节点发送写命令后并不会等待从节点的回复，因此事实上主从节点之间很难保持实时的数据一致性，延迟在所难免，数据不一致的程度和主从节点之间的网络状况、主节点写命令的执行频率以及主节点中的repl-disable-tcp-nodelay配置等有关。

`repl-disable-tcp-nodelay`：该配置作用于命令传播阶段，控制主节点是否禁止与从节点的TCP_NODELAY；默认no，即不禁止TCP_NODELAY。当设置为yes时，TCP会对包进行合并从而减少带宽，但是发送的频率会降低，从节点数据延迟增加，一致性变差；具体发送频率与Linux内核的配置有关，默认配置为40ms。当设置为no时，TCP会立马将主节点的数据发送给从节点，带宽增加但延迟变小。

一般来说，只有当应用对Redis数据不一致的容忍度较高，且主从节点之间网络状态不好的时候，才会设置为yes，多数情况下使用默认值no



### 全量复制和增量复制

全量复制用于初次复制或其他无法进行增量复制（又称为部分复制）的情况，将主节点中的所有数据都发送给从节点，是一个非常重型的操作

增量复制又称部分复制，用于网络中断等情况后的复制，只将中断期间主节点执行的写命令发送给从节点，比全量复制更加高效。

> 值得注意的是，如果网络中断时间过长，导致主节点没有能够完整地保存中断期间执行的写命令，则无法进行部分复制，还是需要进行全量复制



在Redis2.8版本之前，从节点向主节点发送sync命令请求同步数据，此时的同步方式是全量复制，在Redis2.8及以后，从节点向主节点发送psync命令请求同步数据，此时根据主从节点当前状态的不同，同步方式可能是全量复制或者增量复制

**全量复制的过程**

Redis通过psync命令进行全量复制的过程如下：

- 从节点判断无法进行增量复制，向主节点发送进行全量复制的请求，或者从节点发送部分复制的请求，但是主节点判断无法进行部分复制。
- 主节点受到全量复制的请求之后，执行`bgsave`，在后台生成RDB文件，并使用一个缓冲区（称为复制缓冲区）记录从现在开始执行所有写命令
- 主节点的bgsave执行完成后，将RDB文件发送给从节点，从节点首先清除自己的旧数据，然后载入接收的RDB文件，将数据库状态更新至主节点执行bgsave前的数据库的状态
- 主节点将前面所说的复制缓冲区中的所有写命令发送给从节点，从节点执行完这些命令之后，将数据库状态更新至最新状态

- 如果从节点开启了AOF，则会触发`bgrewriteaof`的执行，从而保证AOF文件更新至主节点的最新状态

> 我们知道在进行RDB持久化的时候，主节点是通过bgsave命令**fork一个子进程进行RDB持久化操作**，这个过程是非常消耗CPU、内存、磁盘I/O的，同时主节点将这个RDB文件发送给从节点，会对主从节点的网络带宽也带来一定的影响，此外，从节点清除数据，载入新的RDB文件是一个阻塞过程，这个期间从节点不能够响应任何请求，而且如果从节点开启了aof，那么也会带来额外的消耗
>
> 综上，可以看出，**全量复制是一个非常重型的操作**



**增量复制**

**增量复制的实现依赖于三个重要的概念：复制偏移量、复制积压缓冲区、服务器运行ID**

- 首先是**复制偏移量**，主节点和从节点分别维护一个复制偏移量（offset），代表的是主节点向从节点传递的字节数，主节点每次向从节点传播N个字节数据时，主节点的offset增加N，从节点每次收到主节点传来的N个字节数据时，从节点的offset增加N。

  > **offset用来判断主从节点的数据库状态是否一致，**如果二者offset相同，则一致，如果offset不同，则不一致，此时可以根据两个offset找出从节点缺少的那部分数据，例如主节点的offset是1000，而从节点的offset是500，那么部分复制就需要将offset为501-1000的数据传给从节点，而offset为501-1000的数据存储的位置就是下面要说的复制积压缓冲区

- 第二是**复制积压缓冲区**，**复制积压缓冲区是由主节点维护的、固定长度的、先进先出（FIFO）队列，默认大小为1MB**，当主节点开始有从节点时创建，其作用是备份主节点最近发送给从节点的数据，注意：无论主节点有一个还是多个从节点，**主节点都只需要维护一个复制积压缓冲区**

  在命令传播阶段，主节点除了要将写命令发送给从节点，还要讲这个命令发送一份给复制积压缓冲区，作为写命令的备份，除了存储写命令，复制积压缓冲区中还存储了其中的每个字节对应的复制偏移量，由于复制积压缓冲区是一个先进先出的队列，所以他保存的是主节点最近执行的写命令，**时间较早的写命令会被挤出缓冲区**

  由于缓冲区的长度固定且有限，因此可以备份的写命令也是有限的，**当主从节点offset差距过大超过缓冲区长度时，将无法进行部分复制，这时候只能够进行全量复制**

  从节点将offset发送给主节点之后，主节点根据offset和复制积压缓冲区的大小来决定是否进行增量复制

  - 如果offset偏移量之后的数据仍然在复制积压缓冲区中，那么将进行部分复制
  - 如果offset偏移量之后的数据已经被挤出了缓冲区，那么只能够进行全量复制

  > 从上面我们也可以看出，如果想要提高部分复制的概率，我们可以增大复制积压缓冲区的长度（通过配置repl-backlog-size）
  >
  > 例如如果网络中断的平均时间是60s，而主节点平均每秒产生的写命令(特定协议格式)所占的字节数为100KB，则复制积压缓冲区的平均需求为6MB，保险起见，可以设置为12MB，来保证绝大多数断线情况都可以使用部分复制。

- 第三是**服务器运行ID**，每个Redis节点，无论主从，**都会在启动时自动生成一个随机ID（每次启动都不一样）**，由40个随机的十六进制字符组成，runid用来唯一识别一个Redis节点，通过Info Server命令，来查看节点的runid

  主从节点初次复制时，主节点将自己的runid发送给从节点，从节点将这个runid保存起来，当断线重连时，从节点会将这个runid发送给主节点，主节点也会参考这个runid来判断是否进行部分复制

  - 如果从节点保存的runid和主节点的runid不同的话，说明从节点在断线前同步的Redis节点并不是当前的主节点，只能进行全量复制
  - 如果从节点保存的runid和主节点的runid相同的话，说明主从节点之前同步过，但是能不能够进行部分复制还需要检查offset和复制积压缓冲区的大小



综上，当从节点向主节点发送psync命令之后，数据同步的流程如下：

![img](../../image/redis/1174710-20180628011547892-692403928.png)



> 参考链接 [深入学习Redis（3）：主从复制 - 编程迷思 - 博客园 (cnblogs.com)](https://www.cnblogs.com/kismetv/p/9236731.html)



### 心跳机制

我们知道，主从复制分成了三个部分：连接建立阶段、数据同步阶段、命令传播阶段，在命令传播阶段，主节点除了需要向从节点发送写命令，还维持着**心跳机制：PING和REPLCONF ACK**，心跳机制对于主从复制的超时判断、数据安全等有作用

#### 主节点向从节点发送PING命令

PING发送的频率由repl-ping-slave-period参数控制，单位是秒，默认值是10s。

这个命令的作用就是为了让主节点进行超时判断，如果在规定时间内没有从节点返回值，那么连接就会被断开



#### 从节点向主节点发送REPLCONF ACK命令

在命令传播阶段，从节点会向主节点发送REPLCONF ACK命令，频率是每秒1次，命令格式为REPLCONF ACK{offset}，其中offset指从节点保存的复制偏移量，REPLCONF ACK命令的作用包括：

- **实时监测主从节点的网络状态：**该命令会被主节点用于复制超时的判断。此外，在主节点中使用info Replication，可以看到其从节点的状态中的lag值，代表的是主节点上次收到该REPLCONF ACK命令的时间间隔，在正常情况下，该值应该是0或1，如下图所示：

  ![img](../../image/redis/1174710-20180628011708219-1385546367.png)

- **检测命令丢失：**从节点会发送自身的offset，主节点会与自己的offset对比，如果从节点数据缺失（如网络丢包），主节点会推送缺失的数据（这里也会利用复制积压缓冲区）。offset和复制积压缓冲区不仅可以用于部分复制，还可以用于处理命令丢失等情形，区别在于前者是在断线重连之后进行的，而后者是在主从节点没有断线的情况下进行的

- **辅助保证从节点的数量和延迟：**Redis主节点中使用min-slaves-to-write和min-slaves-max-lag参数，来保证主节点在不安全的情况下不会执行写命令；

  > 所谓的不安全指的是从节点数量太少，或者延迟过高，例如min-slaves-to-write=3,min-slaves-max-lag=10，含义是如果从节点数量小于3，或者所有从节点的延迟都大于10s，则主节点拒绝执行写命令

  而这里，从节点延迟值得获取就是通过主节点接收到REPLCONF ACK命令的时间来判断的，即前面所说的info Replication中的lag值



### 主从复制的使用

**<font color=red>主从复制的开启，完全是由从节点发起的，不需要我们在主节点做任何事情</font>**

从节点开启主从复制，有以下三种方式：

- **配置文件**

  永久有效，在从服务器配置文件中加入`slaveof/replicaof <masterip> <masterport>`，指定主机的ip地址和端口

- **启动命令**

  redis-server启动命令后加入`--salveof <masterip> <masterport>`

- **客户端命令**

  Redis服务器启动之后，直接通过客户端执行命令：`slaveof <masterip> <masterport>`，则该redis实例成为从节点





## Redis集群







## Redis哨兵











