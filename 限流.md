## 限流

[toc]



限流，也称流量控制，是指系统在面临高并发，或者大流量请求的情况下，限制新的请求对系统的访问，从而保证系统的稳定性。限流会导致部分用户请求处理不及时或者被拒，这就影响了用户体验，所以一般需要在系统稳定和用户体验之间平衡一下。



### 常见的限流算法

#### 固定窗口限流算法

核心思想是：维护一个计数器，将单位时间段当作一个窗口，计数器记录这个窗口接受请求的次数。如果单位时间内的请求次数小于限流阈值，允许访问，反之则不允许。在时间窗口结束之后，计数器会重新计数。

<img src="./image/limit/fixedWindow.jfif" style="zoom:50%;" />

```java
public class FixedWindow {
    private static final Integer QPS = 5; // 阈值
    private static final long TIME_WINDOWS = 1000; // 时间窗口
    private static AtomicInteger REQUEST_COUNT = new AtomicInteger(); // 请求计数器

    private static long STATE_TIME = System.currentTimeMillis();

    public synchronized static boolean tryAcquire() {
        if (System.currentTimeMillis() - STATE_TIME > TIME_WINDOWS) {
            REQUEST_COUNT.set(0); // 重新计数
            STATE_TIME = System.currentTimeMillis();
        }

        return REQUEST_COUNT.incrementAndGet() <= QPS;
    }
}
```

但是这种方法有一种很明显的临界问题，假设限流阈值为5个请求，单位时间窗口是1s，如果我们在单位时间内的前0.8s-1s和1-1.2s，分别并发5个请求。虽然都没有超过阈值，但是0.8-1.2s的并发数已经高达10，已经超过了单位时间1s不超过5的阈值了

<img src="./image/limit/fixedWindow2.jfif" style="zoom:50%;" />



#### 滑动窗口限流法

滑动窗口限流解决固定窗口临界值的问题，它将单位时间周期分成n个小周期，分别记录每个小周期内接口的访问次数，并且根据时间滑动删除过期的小周期。

<img src="./image/limit/slideWindow.jfif" style="zoom:50%;" />

假设单位时间还是1s，滑动窗口算法把它划分成5个小周期，也就是滑动窗口（单位时间）被划分为5个小格子，每格表示0.2s，没过0.2s，时间窗口就会往右滑动一个，然后每个小周期都有自己独立的计数器，如果请求是0.83s到达的，0.8-1.0s对应的计数器就会加1

假设，我们1s内的限流阈值还是5个请求，0.8-1.0s内来了5个请求，落在上面的黄色格子中，时间过了1.0s之后，又来了5个请求，落在紫色格子里。如果是固定窗口算法，是不会被限流的，但是滑动窗口的话，每过一个小周期，它会右移一个小格，过了1.0s这个点后，会右移一小格，当前的单位时间段是0.2-1.2s，这个区域的请求已经超过限定的5了，已经触发限流了，因此实际上，紫色格子的请求都会被拒绝。

```java
class SlidingWindow {
    private static Integer QPS = 2; // 阈值
    private static final long TIME_WINDOWS_SIZE = 1000; // 时间窗口总大小

    private static final Integer SUB_WINDOW_COUNT = 10; // 子窗口个数(一个时间单位分成10份)

    private WindowInfo[] subWindowArray = new WindowInfo[SUB_WINDOW_COUNT];

    public SlidingWindow() {
        long currentTimeMillis = System.currentTimeMillis();
        for (int i = 0; i < subWindowArray.length; i++) {
            subWindowArray[i] = new WindowInfo(currentTimeMillis, new AtomicInteger(0));
        }
    }

    /**
     * 1. 计算当前时间窗口
     * 2. 更新当前窗口计数 & 重置过期窗口计数
     * 3. 当前QPS是否超过限制
     * @return
     */
    public synchronized boolean tryAcquire() {
        long currentTimeMillis = System.currentTimeMillis();
        // 1. 计算当前时间窗口
        int currentIdx = (int) (currentTimeMillis % TIME_WINDOWS_SIZE / (TIME_WINDOWS_SIZE / SUB_WINDOW_COUNT));
        // 2. 更新当前窗口计数 & 重置过期窗口计数
        int sum = 0;
        for (int i = 0; i < subWindowArray.length; i++) {
            WindowInfo windowInfo = subWindowArray[i];
            if (currentTimeMillis - windowInfo.getTime() >= TIME_WINDOWS_SIZE) {
                windowInfo.getCounter().set(0);
                windowInfo.setTime(currentTimeMillis);
            }

            if (currentIdx == i && windowInfo.getCounter().get() < QPS) {
                windowInfo.getCounter().incrementAndGet();
            }

            sum += windowInfo.getCounter().get();
        }

        // 当前QPS是否超过限制
        return sum <= QPS;
    }


    private class WindowInfo {
        private Long time; // 窗口开始时间
        private AtomicInteger counter; // 计数器

        public WindowInfo(Long _time, AtomicInteger _counter) {
            this.time = _time;
            this.counter = _counter;
        }

        public Long getTime() {
            return time;
        }

        public void setTime(Long time) {
            this.time = time;
        }

        public AtomicInteger getCounter() {
            return counter;
        }

        public void setCounter(AtomicInteger counter) {
            this.counter = counter;
        }
    }
}
```



#### 滑动日志算法

滑动日志算法是实现限流的另一种方法，基本逻辑就是记录下所有的请求时间点，新请求到来时先判断最近指定时间范围内的请求数量是否超过指定阈值，由此来确定是否达到限流，这种方式没有了时间窗口突变的问题，限流比较准确，但是因为要记录下每次请求的时间点，所以占用的内存较多。



#### 漏桶算法

漏桶算法的原理可以认为是注水漏水的过程，往漏桶中以任意速率流入水，以固定的速率流出水，当水超过桶的容量时，会被溢出，因为桶的容量是不变的，保证了整体的速率。

<img src="./image/limit/leakyBucket.jfif" style="zoom:50%;" />

- 流入的水滴可以看作是访问系统的请求，这个流入速率是不确定的
- 桶的容量一般表示系统所能处理的请求数
- 如果桶的容量满了，就达到限流的阈值，就会丢弃水滴（拒绝请求）
- 流出的水滴是恒定速率的，对应服务按照固定的速率处理请求

```java
class LeakyBuckets {
    private static final Integer rate = 3; // 漏水速率
    private long currentWater; // 初始剩余水量
    private long refreshTime;  // 后刷新时间
    private static final long capacity = 1000; // 桶容量

    public boolean tryAcquire() {
        long currentTime = System.currentTimeMillis();
        long outWater = (currentTime - refreshTime) / 1000 * rate; // 这段时间区间内处理的请求数
        currentWater = Math.max(0, currentTime - outWater);
        refreshTime = currentTime;
        // 剩余水量还没有达到阈值
        if (currentWater < capacity) {
            currentWater++;
            return true;
        }
        
        return false;
    }
}
```

显然，在正常流量的时候，系统按照固定的速率处理请求，这是我们想要的。但是**面对突发流量**的时候，漏桶算法还是会按部就班的处理请求，这就会降低用户体验了，因为当面临流量突增时，我们是希望尽快处理请求的。



#### 令牌桶算法

面对突发流量时，我们可以使用令牌桶算法进行限流

- **系统服务作为生产者，按照指定频率向桶（容器）中添加令牌**，如QPS为2，每500ms向桶中添加一个令牌，如果桶中令牌数量达到阈值，则不再添加
- **请求执行作为消费者，每次请求都需要去桶中拿取一个令牌，**取到令牌则继续执行；如果桶中无令牌可取，就触发拒绝策略，可以是超时等待，也可以是直接拒绝本次请求，由此达到限流目的

<img src="./image/limit/tokenBucket.jfif" style="zoom:50%;" />

令牌桶算法具有两个重要的特性：**流量整形**和**方便处理突发流量**

- 流量整形是指令牌桶算法通过阻塞、拒绝等手段使请求以稳定的速度通过限流器，原本不规则的流量在经过限流器后变得平滑且均匀。流量整形效果非常有利于服务端稳定运行，类似我们在高并发系统中常用的基于消息队列实现的“削峰填谷”手段，经过整形后，服务端能够以稳定的状态接收并处理请求。
- 突发流量是指随机出现的、短时间的流量突刺。如果严格遵循流量整形的限制，那么服务端再遇到突发流量时会突然拒绝一大波请求，在客户端有重试机制的情况下还可能导致情况进一步恶化。因此在服务端资源充足的条件下，限流器应该具有一些“弹性”，**允许服务器临时超频处理一些突发请求。**



### Guava

#### 概述

最为常用的Google的Java开发工具包Guava中的限流工具类`RateLimiter`（单机限流工具）就是令牌桶的一个实现。

Guava限流器的使用非常简单，下面来看两个case

```java
// case 1：将一个队列中的任务以不超过每秒两个的速度提交执行
final RateLimiter rateLimiter = RateLimiter.create(2.0); // rate = 2 permits per second

void submitTasks(List<Runnable> tasks, Executor executor) {
  for (Runnable task : tasks) {
    rateLimiter.acquire();  // may wait
    executor.execute(task);
  }
}


// case 2：某个业务场景要求发送数据的速度不超过每秒5KB（根据数据大小或请求权重来进行限速）
final RateLimiter rateLimiter = RateLimiter.create(5000.0); // rate = 5000 permits per second

void submitPacket(byte[] packet) {
    rateLimiter.acquire(packet.length);
    networkService.send(packet);
}
```

Guava限流器中内置了两种模式来应对不同的限流场景，分别是**突发模式（稳定模式，SmoothBursty）**和**预热模式（渐进模式，SmoothWarmingUp）**，在上述案例中，我们通过create方法创建的限流器时默认的突发模式，它的特点是限流器在空闲状态下会保存一部分令牌，用于后续处理突发请求，从而避免大量阻塞或拒绝。除此之外，用户也可以通过其他方法创建出预热模式的限流器，预热模式适用于大流量场景，可以让服务端从空闲状态平滑过渡到高负载状态。

在这里我们通过一个问题来引入两种模式：**如果按照指定间隔添加令牌，那么需要开一个线程去定时添加，如果有很多个接口很多个RateLimiter实例，线程数会随之增加，这显然不是一个好的办法。**

Google也考虑到了这个问题，他们是这样解决的：在RateLimiter中，是在每次令牌获取时才进行计算令牌是否足够，它通过存储下一个令牌生成的时间和当前获取令牌的时间差，再结合阈值，去计算令牌是否足够，同时再记录下一个令牌的生成时间以便下一次调用。

下面是源码中的计算逻辑

```java
final long reserveEarliestAvailable(int requiredPermits, long nowMicros) {
  //1.计算令牌桶中的令牌数量
  resync(nowMicros);
  
  //2.发放令牌
  long returnValue = nextFreeTicketMicros;
  double storedPermitsToSpend = min(requiredPermits, this.storedPermits);
  double freshPermits = requiredPermits - storedPermitsToSpend;
  //预计等待时间 = 桶内令牌发放时间 + 后续生成令牌所需时间
  long waitMicros = storedPermitsToWaitTime(this.storedPermits, storedPermitsToSpend) + (long) (freshPermits * stableIntervalMicros);
  this.nextFreeTicketMicros = nextFreeTicketMicros + waitMicros;
  this.storedPermits -= storedPermitsToSpend;
  return returnValue;
}

private void resync(long nowMicros) {
  if (nowMicros > nextFreeTicketMicros) {
    //桶内令牌数 = min(桶容量， 剩余令牌数 + 空闲时间内生成的令牌数)
    storedPermits = min(maxPermits, storedPermits + (nowMicros - nextFreeTicketMicros) / stableIntervalMicros);
    nextFreeTicketMicros = nowMicros;
  }
}
```

<img src="./image/limit/tokenTime.jfif" style="zoom:60%;" />

在上述令牌桶计算过程中还有一个请求阻塞等待的优化，就是方法返回的放行时间增加了**等待耗时（waitMicros）**，这样做的效果是阻塞等待不会影响当前的请求，而是影响后续等待时长内到达的请求。举例来说，假设有个1QPS的限流器，收到了一个需要100个令牌才能通过的请求。这种情况下两种处理方案：一是先放行这个请求让服务端处理，之后100秒内阻塞后续到达的请求，二是直接阻塞当前请求100秒后再放行。显然第一种处理方式对请求处理更加友好，能够以更小的阻塞代价达到同样的限流效果。读者也可以参考下面这段Guava源代码中的注释来理解这种“**赊账**”机制所带来的收益。

可以看到等待耗时（waitMicros）的计算除了包含了生成新令牌所需时间（freshPermits）之外，还包含了以storedPermitsToWaitTime方法计算的**发放桶内令牌（storedPermitsToSpend）的时间**。为什么发放桶内已有令牌还需要计算耗时呢？

实际上，**桶内令牌发放时间的计算是由限流器的模式决定的。**上文中有提过，Guava限流器包含突发和预热两种模式，这两种模式分别建立了不同的桶内令牌发放模型，并基于各自的模型来计算方法耗时。下面将详细介绍这两种令牌发放模型。

> 应该是因为赊账机制导致的waitMicros包含两部分



#### 突发模式

在突发模式中，Guava限流器的桶中令牌是有一个有效期的，有效期的作用是让限流器具有一定的弹性，可以根据空闲情况临时超额放行一些请求用于平滑处理突发流量

因此，突发模式下的桶内令牌发放模型非常简单，可以直接发放，不需要计算开销。实现代码如下所示：

```java
static final class SmoothBursty extends SmoothRateLimiter {  
    @Override
    long storedPermitsToWaitTime(double storedPermits, double permitsToTake) {
      return 0L;
    }
}
```



#### 预热模式

预热模式比较复杂，在预热过程中，限流器通过请求的速度会随着流量的上涨而逐渐加快，目的是让服务端平滑地从空闲状态过渡到高负载状态。

在限流器预热模式下，桶内令牌是一个逻辑概念，仅用来界定限流器的冷热状态，所有发放的令牌都需要重新生成，且在**预热过程中令牌还是变速生成的**。因此，预热模式下的令牌发放时间需要根据预热模型的具体定义来计算。

<img src="./image/limit/warmUp.jfif" style="zoom:50%;" />

上图即为Guava限流器所定义的预热模型，它来自Guava代码的注释，图中展示了预热过程中令牌桶中令牌数量（横轴）与限流器令牌生成的时间间隔（纵轴）的对应关系。当桶内令牌数量较多时，说明此时流量较小，限流器处于冷状态，令牌生成速度较慢，最慢为原速度的1/3（3*stable interval，即三倍的令牌生成间隔时间）。当流量变大时，桶内的令牌会被逐渐消耗，限流器由冷状态逐渐变为热状态，令牌生成速度逐渐增加，直到桶内剩余1/2令牌（halfPermits）时，限流器令牌生成恢复原速，进入稳定状态。



了解预热模型之后，就可以回到我们的时间计算问题了，假设当前令牌桶内的令牌数为n，请求通过需要的令牌数为m，那么计算下图中区间[n-m,n]的面积，即为发放m个令牌所需的时间（积分），下面是预热模式的代码实现，可以看到，它的计算过程就是求上图中的区间面积，代码以halfPermits为分界线，分别计算了左边的矩形面积与右边的梯形面积，二者之和即是预热过程中的发放令牌耗时

```java
static final class SmoothWarmingUp extends SmoothRateLimiter {
    private final long warmupPeriodMicros;
    private double slope;        //预热模型中，梯形斜边的斜率
    private double halfPermits; 
  
    @Override
    long storedPermitsToWaitTime(double storedPermits, double permitsToTake) {
      double availablePermitsAboveHalf = storedPermits - halfPermits;
      long micros = 0;
      // measuring the integral on the right part of the function (the climbing line)
      // 预热期发放令牌的时间，即梯形的面积
      if (availablePermitsAboveHalf > 0.0) {
        double permitsAboveHalfToTake = min(availablePermitsAboveHalf, permitsToTake);
        micros = (long) (permitsAboveHalfToTake * (permitsToTime(availablePermitsAboveHalf)
            + permitsToTime(availablePermitsAboveHalf - permitsAboveHalfToTake)) / 2.0);
        permitsToTake -= permitsAboveHalfToTake;
      }
      // measuring the integral on the left part of the function (the horizontal line)
      // 稳定期发放令牌的时间，即矩形的面积
      micros += (stableIntervalMicros * permitsToTake);
      return micros;
    }
  
    private double permitsToTime(double permits) {
      return stableIntervalMicros + permits * slope;
    }
}
```



### 常见限流场景的解决方案

#### 场景1: 服务端接口限制被调用的速度

**解决方案：**可以使用Guava限流器突发模式，配合非阻塞方法tryAcquire限制被调用速度，无特殊需要情况下，tryAcquire超时时间建议为0

**补充说明：**突发模式的突发时间（maxBrustSeconds）配置可根据接口历史流量的波动情况确定，多数场景中设置1～5秒即可。突发时间不建议设置为0，可能导致一些不符合预期的拒绝行为。另外，一般情况下，不建议在服务端接口使用限流的acquire或tryAcquire方法做阻塞等待，这样会增加请求延迟，给调用方带来不好的体验。



#### 场景2: 客户端限制发出请求的速度

**解决方案：**可以使用Guava限流器突发模式，配合阻塞方法acquire限制发出请求的速度

**补充说明：**无特殊需求的情况下，突发时间（maxBrustSeconds）可配置为0，配合acquire的流量整形效果让客户端发出匀速请求。另外，如果客户端存在失败重试机制，那么可能需要考虑一下重试间隔会由于限流器的阻塞而被拉长的问题。

突发时间是否配置，应该是是否使用“赊账”机制，对应着能够应对突发的流量



#### 场景3: 秒杀或大促业务场景中，保护服务端不被大流量打垮

**解决方案：**可以使用Guava限流器预热模式，配合非阻塞方法tryAcquire做流量控制，建议设置一个合适的tryAcquire超时时间

**补充说明：**预热时间长度可根据业务场景特点配置，限流阈值可通过事先的接口压测来确定。这里建议使用tryAcquire进行可超时阻塞的目的是为了保证业务中“先到先得”的公平性























